#!/usr/bin/env python 

"""Manipulation of regular and context free languages."""

from __future__ import division

from pprint import pprint
import string
import sys
import random

import nltk
from nltk.grammar import parse_cfg, Nonterminal, ContextFreeGrammar, Production

from cnf import convert_to_cnf

class CFLGeneration(object):
    """Random string generation from the language generated by input grammar.
    """

    def __init__(self, grammar, length=1):
        """Convert the grammar to Chomsky Normal Form and do preprocessing.
        
        `grammar` can be:
            (1) an instance of nltk.grammar.ContextFreeGrammar,
            (2) a string representing the path to a .cfg file, or
            (3) a string that can be parsed into a grammar by parse_cfg

        `length` is the maximum string length that should be preprocessed.
        """
        self.length = length

        # self.grammar must be instance of nltk.grammar.Grammar
        if isinstance(grammar, ContextFreeGrammar): #TODO: is CFG base class?
            self.grammar = grammar
        elif isinstance(grammar, str) and grammar.endswith('.cfg'):
            self.grammar = nltk.data.load('file:' + grammar)
        elif isinstance(grammar, str):
            self.grammar = parse_cfg(grammar)
        else:
            raise ValueError('Arg grammar must be nltk.grammar.Grammar or str.')
        
        if not self.grammar.is_chomsky_normal_form():
            self.grammar = convert_to_cnf(self.grammar)

        self.productions = self.grammar.productions()

        # NOTE: Is it ok to assume all nonterminals occur on a LHS?
        self.nonterminals = set([p.lhs() for p in self.productions])

        self.terminals = set()
        for prod in self.productions:
            for token in prod.rhs():
                if not isinstance(token, Nonterminal):
                    self.terminals.add(token)

        # Initialize _counts then populate it in _preprocess().
        self._counts = {}
        self._preprocess()

    def count_by_nonterm(self, nonterm, length):
        """Return number of strings of length `length` derivable from `nonterm`.
        """
        if isinstance(nonterm, basestring):
            nts = [nt for nt in self.nonterminals if nt.symbol == nonterm]
            if not nts:
                raise KeyError("nonterm isn't in grammar.")
            (nonterm,) = nts
        return self._counts[nonterm][length]

    def count_by_prod(self, prod, length):
        """Return the number of strings of length `length` derivable from the
        RHS of `prod`."""
        assert isinstance(prod, Production)
        assert len(prod.rhs()) < 3

        if isinstance(prod.rhs()[0], basestring):
            if length == 1:
                return 1
            else:
                return 0

        B, C = prod.rhs()[0], prod.rhs()[1]
        return sum([self.count_by_nonterm(B, k) *  
                    self.count_by_nonterm(C, length - k)
                    for k in range(1, length)])


    def generate(self, length):
        """Return a string of length `length` that is in L(self.grammar)."""
        # Update self._counts for string lengths up to `length` if necessary.
        if length > self.length:
            print 'updating counts'
            self._update_counts(length)

        # TODO: GENERATION
        start = self.grammar.start()
        pprint(self._counts, indent=3)
        return self._generate_rec(start, length)


    def _generate_rec(self, nonterm, length):
        print '#### _generate_rec(%s, %d)' % (nonterm.symbol(), length)

        if length == 1:
            productions = self._prods_by_lhs(nonterm)
            terminals = [p.rhs()[0] for p in productions if len(p.rhs()) == 1]
            if productions and not terminals:
                print productions
                print terminals
                raise Exception("SHIT")
            print 'There are %d choices for terminal: %s' % \
                    (len(productions), str(productions))
            choice = random.choice(terminals)
            print "TERMINAL CHOICE IS", choice
            return choice

        #TODO: use listcomps
        for prod in self._prods_by_lhs(nonterm):
            count = self.count_by_prod(prod, length)
        productions = [prod for prod in self._prods_by_lhs(nonterm)
                       if self.count_by_prod(prod, length) > 0]
        probabilities = []
        for prod in productions:
            numerator = self.count_by_prod(prod, length)
            denominator = self.count_by_nonterm(prod.lhs(), length)
            if denominator != 0: 
                probabilities.append(numerator / denominator)
        #print 'production probabilities:', zip(productions, probabilities)
        print 'Choose for productions:', productions
        production = _choose(zip(productions, probabilities))
        print "Chose production", production
        if production is None:
            raise Exception("FAILURE TO PRODUCE")
        
        first, second = production.rhs()[0], production.rhs()[1]
        # Calculate split
        split_probs = []
        for k in range(1, length):
            numerator1 = self.count_by_nonterm(first, k)
            numerator2 = self.count_by_nonterm(second, length - k)
            denominator = self.count_by_prod(production, length)
            prob = (numerator1 * numerator2) / denominator
            split_probs.append((k, prob))
        print 'Choose for split'
        split = _choose(split_probs)

        print 'SPLIT is', split

        left = self._generate_rec(production.rhs()[0], split)
        right = self._generate_rec(production.rhs()[1], length - split)
        assert isinstance(left, basestring)
        assert isinstance(right, basestring)
        return left + right



    def _prods_by_lhs(self, lhs):
        assert isinstance(lhs, Nonterminal)
        return set([p for p in self.productions if p.lhs() == lhs])


    def _update_counts(self, new_length):
        """Extend self._counts to cover strings of length `new_length`."""
        if self.length >= new_length:
            return

        # Extend the count lists with 0s
        diff = new_length - self.length
        for key, value in self._counts.iteritems():
            value += [0 for i in range(diff)]

        for L in range(self.length + 1, new_length + 1):
            print L
            for nonterm in self.nonterminals:
                print '****Nonterm=%s, length=%d' % (str(nonterm), L)
                #TODO: switch back to genexp
                prods = [p for p in self._prods_by_lhs(nonterm) 
                         if len(p.rhs()) == 2]

                print 'Potential prods:', prods
                # Handle productions of form A -> B C. Increment the count of
                # strings of length L derivable from A by the number of ways 
                # that B and C can combine to form a string of length L.
                for prod in prods:
                    print 'prod=', prod
                    B = prod.rhs()[0]
                    C = prod.rhs()[1]
                    for k in range(1, L):
                        left = self._counts[B][k]
                        right = self._counts[C][L - k]
                        print 'length=%d, old=%d, left=%d, right=%d' % \
                              (L, self._counts[nonterm][L], left, right)
                        self._counts[nonterm][L] = self._counts[nonterm][L] +  \
                                                   left * right
                        #print "Setting count for '%s' of len %d at %d" % \
                        #       (str(nonterm), L, self._counts[nonterm][L] + left + right)

        # Check that the number of counts for a nonterminal is equal to
        # `new_length` (with 1 added for the None value). Then reset self.length
        # to reflect that.
        assert len(self._counts.itervalues().next()) == new_length + 1
        self.length = new_length
        print '\n' + '*' * 5,
        print 'EXITING _update_counts',
        print '*' * 5
        print

    def _preprocess(self):
        """Populate self._counts.

        _counts is a dict from nltk.grammar.Nonterminal to lists. Each index
        in the list holds the number of strings of length index that can be
        generated starting from the Nonterminal.
        """
        # Set the counts for all lengths for each nonterminal to 0.
        for nonterm in self.nonterminals:
            self._counts[nonterm] = [None] + [0 for i in range(self.length)]

        # For each production A -> 'a', increment the number of strings of
        # length one that can be generated from A.
        for prod in [p for p in self.productions if len(p.rhs()) == 1]:
            self._counts[prod.lhs()][1] += 1

        # Recursively find and set counts for lengths up to self.length
        self._update_counts(self.length)



def _choose(pairs):
    """Choose at random from items and their probabilities of being chosen.

    pairs = [(item, probability), ...]
    """
    assert pairs
    the_sum = sum([pair[1] for pair in pairs])
    if the_sum == 0:
        return None
    if not .99 < the_sum < 1.01:
        raise ValueError('Probabilities must add to 1.')
        # NOTE: I should put in a range for this since sum won't be exact.
    r = random.uniform(0, the_sum)
    current = 0
    for (item, prob) in pairs:
        current += prob
        if r <= current:
            return item
     


def test_convert():
    g = nltk.data.load('file:noncnf.cfg')
    print '*' * 12 + '\n' +  str(g) + '\n' + '*' * 12
    cnf = convert_to_cnf(g)


class RegexToCFG(object):
    """Conversion of basic REs to their corresponding CFGs.
    """
    
class StubError(Exception):
    pass


def test_gen():
    #generator = CFLGeneration('g.cfg', 3)
    #generator = CFLGeneration('g.cfg')
    generator = CFLGeneration('sentence.cfg')
    s = generator.generate(5)
    print s
    #print;print
    #for prod in generator.productions:
    #    for L in range(1, 5):
    #        count = generator.count_by_prod(prod, L)
    #        print "'%s' with length %d = %d" % (str(prod), L, count)
    #    print
    #pprint(generator._counts, indent=3)

def main():
    pass

if __name__ == '__main__':
    test_gen()
